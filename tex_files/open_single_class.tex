\section{Open Single-Class Product-Form Networks}
\label{sec:jackson-networks}


Up to now our analysis focused on single-station queueing systems.
In many practical situations, however, jobs in a factory or patients in a hospital have to undergo several process steps before they are `finished'.
One of the simplest models to analyze such situations is to assume that jobs arrive as a Poisson processes, and the service times are exponentially distributed.
We will see that it is possible to obtain closed-form expressions for the stationary distribution of jobs at each station.
To establish this we will first concentrate on two stations in tandem, and then extend to general networks.
We remark that in~\cref{sec:tandem-queues} we considered tandem networks of $G/G/c$ queues, but there we could only obtain insight in the expected times, not the full distribution of the number of jobs at each station.

\subsection*{Theory and Exercises}

\opt{solutionfiles}{
\Opensolutionfile{hint}
\Opensolutionfile{ans}
}



\subsubsection{Tandem Queues}

In~\cref{ex:burke} (and the intermediate exercises leading to that result) we (ask you to) prove that the inter-departure times of an $M/M/1$ queue are also exponentially distributed with rate $\lambda$.
This is useful because when the first station is an $M/M/1$ queue, this implies that the arrival process at the second station is also an $M/M/1$ queue.
Stated differently, from the perspective of the second station, it is as if there is no first station.
And, if there is a third station with exponentially distributed service times, this also behaves as an $M/M/1$ queue, and so on.
With this insight, it is easy to see that the average total waiting time in a tandem network of $M$ stations equals
\begin{equation*}
  \E{W} = \sum_{i=1}^M \frac{\E{S_i}}{1-\rho_i},
\end{equation*}
where $\rho_i = \lambda \E{S_i}$, and $\E{S_i}/(1-\rho_i)$ is the expected waiting time at station~$i$; note that the arrival rate at each station is $\lambda$, due to the topology of the network, i.e., a tandem network.

\begin{extra}\clabel{ex:dep}
Why is the output rate of the (stable) $M/M/1$ queue equal to~$\lambda$ and not~$\mu$?
\begin{solution}
  Jobs arrive at rate $\lambda$.
  For a stable queue, $\mu>\lambda$.
  Moreover, jobs can never leave faster than they arrive.
  Note that, when there are jobs \emph{present} at station 1, jobs do leave at rate $\mu_1$.
  However, there are not always jobs in service, and during such times, there are no job departures.
\end{solution}
\end{extra}


\begin{extra}
 Why is $\mu e^{-\mu t}$ not a reasonable density for the inter-departure times?
 In fact, the simplest guess for the inter-departure density might be $\lambda e^{-\lambda t}$; so this is what we will try to prove below.
We will focus on departure moments and use~\cref{eq:39}, in particular that departures `see' what arrivals `see', i.e., $\delta(n)= \pi(n)$, and PASTA.
\begin{solution}
 Because jobs do not leave at rate $\mu$. 
\end{solution}
\end{extra}




\begin{extra}\clabel{ex:28}
Show that the probability that a job leaves behind a busy station is $\rho$, hence $1-\rho$ is the probability to leave an idle server behind.
\begin{solution}
Observe that $\rho$ is the fraction of time the server is busy. Then, from PASTA, the fraction of jobs that see a busy server is also $\rho$. This fraction of jobs is $\sum_{n=1}^\infty \pi(n)$. Finally, $\delta(n) = \pi(n)$ , a fraction $\rho$ of the departures leaves a busy system behind.

\end{solution}
\end{extra}


\begin{extra}\clabel{ex:17}
 If job $n-1$, say, leaves behind an empty system, show that the expected time until the next departure is $\E{D_n - D_{n-1}} = 1/\lambda + 1/\mu$. 
\begin{hint}
 After job $n-1$ left, job $n$ has to arrive, so we need to wait first for this inter-arrival time. Then job $n$ must be served. This adds up to $1/\lambda + 1/\mu$. 
\end{hint}
\begin{solution}
With the hint, we first have to wait for an inter-arrival
 time $X_n$. Then, since job $n$'s service starts right away, it
 leaves when $D_n = D_{n-1}+X_n + S_n$. Now observe that, due to the memoryless property of the inter-arrival times, $\E{X_n} = \E{A_n - D_{n-1}} = 1/\lambda$. Thus, the expected duration is $\E{X_n + S_n}=1/\lambda + 1/\mu$. 
\end{solution}
\end{extra}

\begin{extra}
Show that the density of $D_{n} - D_{n-1}$ is
 \begin{equation*}
 f_{X+S}(t) = \frac{\lambda \mu}{\lambda - \mu} (e^{-\mu t} - e^{-\lambda t})
 \end{equation*}
if the server is idle after $D_{n-1}$.
\begin{solution}
 By the previous point, the density of $D_{n} - D_{n-1}$ is the
 same as the density of $X_n + S_n$. Since $\{X_n\}$ and $\{S_n\}$ are both i.i.d. sequences, the problem becomes to find the density of $X+S$. We will use two ways of computing this. 

Since $X\sim \Exp(\lambda)$ and $S\sim\Exp(\mu)$, and $X$ and $S$ are independent, their joint density is $f_{X,S}(x,y) = \lambda \mu e^{-\lambda x - \mu y}$. With this,
 \begin{align*}
\P{X+S\leq t } 
&= \lambda \mu \int_0^\infty \int_0^\infty e^{-\lambda x - \mu y} \1{x+y\leq t} \d x \d y \\
&= \lambda \mu \int_0^t \int_0^{t-x} e^{-\lambda x - \mu y} \d y \d x \\
&= \lambda \mu \int_0^t e^{-\lambda x} \int_0^{t-x} e^{- \mu y} \d y \d x \\
&= \lambda \int_0^t e^{-\lambda x} (1-e^{- \mu (t-x)} ) \d x \\
&= \lambda \int_0^t e^{-\lambda x} \d x - \lambda e^{-\mu t} \int_0^t e^{(\mu-\lambda) x} \d x \\
&= 1- e^{-\lambda t} - \frac{\lambda}{\mu-\lambda} e^{-\mu t} ( e^{(\mu-\lambda) t} -1) \\
&= 1- e^{-\lambda t} - \frac{\lambda}{\mu-\lambda} e^{-\lambda t} + \frac{\lambda}{\mu-\lambda} e^{-\mu t} \\ 
&= 1 - \frac{\mu}{\mu-\lambda} e^{-\lambda t} + \frac{\lambda}{\mu-\lambda} e^{-\mu t}. \\
 \end{align*}
The density $f_{X+S}(t)$ is the derivative of this expression with respect to~$t$, hence,
\begin{align*}
 f_{X+S}(t) 
&= \frac{\lambda\mu}{\mu-\lambda} e^{-\lambda t} - \frac{\mu \lambda}{\mu-\lambda} e^{-\mu t} \\
&= \frac{\lambda\mu}{\lambda -\mu}(e^{-\mu t} - e^{-\lambda t}). \\
\end{align*}

Conditioning is much faster, but requires the concept of conditional density. You can skip the rest if you are not interested. 
 \begin{align*}
 f_{X+S}(t) 
&= \P{X+S\in \d{t}} \\
&= \int \P{S+x\in \d{t}}\P{X\in \d{x}} \\
&=\int_0^t f_S(t-x) f_X(x) \d{x} \\
 &= \int_0^t \mu e^{-\mu(t-x)} \lambda e^{-\lambda x} \d{x} \\
 &= \lambda \mu e^{-\mu t} \int_0^t e^{x(\mu-\lambda)} \d{x} \\
&= \frac{\lambda \mu}{\lambda - \mu}\left(e^{-\mu t} - e^{-\lambda t}\right).
 \end{align*}
\end{solution}
\end{extra}


\begin{extra}
Show that when the queue is not empty at a departure time, the density of the next inter-departure time is $f_D(t) = \mu e^{-\mu t}$.
\begin{solution}
After the departure, the server can start right away with the job at the head of the queue. The inter-departure time of this job is $\Exp(\mu)$.
\end{solution}
\end{extra}

\begin{extra}\clabel{ex:63}
Use conditioning on the server being idle or busy at a departure to show that the density of the inter-departure time is $\lambda e^{-\lambda t}$.
\begin{hint}
Conditioning leads to 
\begin{equation*}
 f_D(t) = f_{X+S}(t) \P{\text{server is idle}} + f_S(t) \P{\text{ server is busy }}= (1-\rho) f_{X+S}(t) +
 \rho \mu e^{-\mu t}.
\end{equation*}
 Now use the above exercises to simplify.
\end{hint}
\begin{solution}
 \begin{align*}
 f_D(t) 
&= (1-\rho) f_{X+S}(t) + \rho \mu e^{-\mu t} \\
&= (1-\rho) \frac{\mu\lambda}{\lambda-\mu} \left(e^{-\mu t}-e^{-\lambda t}\right) + \rho \mu e^{-\mu t} \\
&= \left(1-\frac{\lambda}\mu\right) \frac{\mu\lambda}{\lambda-\mu}\left(e^{-\mu t}-e^{-\lambda t}\right) + \rho \mu e^{-\mu t} \\
&= \frac{\mu-\lambda}\mu \frac{\mu\lambda}{\lambda-\mu}\left(e^{-\mu t}-e^{-\lambda t}\right) + \frac\lambda \mu \mu e^{-\mu t} \\
% &= \frac{\mu-\lambda}\mu \frac{\mu\lambda}{\lambda-\mu}\left(e^{-\mu t}-e^{-\lambda t}\right) + \lambda e^{-\mu t} \\
&= - \lambda\left(e^{-\mu t}-e^{-\lambda t}\right) + \lambda e^{-\mu t} \\
&= \lambda e^{-\lambda t}.
 \end{align*}
\end{solution}
\end{extra}


\begin{exercise}\clabel{ex:burke}
Assuming that  inter-departure times are independent,  prove \recall{Burke's law} which states that the departure process of the $M/M/1$ queue is a Poisson process with rate $\lambda$.
\begin{solution}
  It follows from~\cref{ex:dep} to~\cref{ex:63} that inter-departures times have the same density function $\lambda e^{-\lambda t}$.
  The independence of inter-departure times is assumed.
  These two facts combined imply that the departure process forms a Poisson process with rate $\lambda$.
\end{solution}
\end{exercise}


\subsubsection{Open Networks of $M/M/1$ queues}
It is not difficult to extend the above result for tandem networks to general networks  of $M/M/1$ queues.
For this, we first need to model such networks more formally.
In particular, we assume that the probability that a job moves to station~$j$ after completing its service at station~$i$ is independent of anything else, and is given by the number $P_{i j}\in[0,1]$.
(This is called Markov routing.)
We assemble all these probabilities in a \emph{routing matrix} $P$ such that $P_{i j}$ is the element of $P$ on the $i$th row and $j$th column.
We require that $\sum_{j=1}^M P_{i j} \in [0, 1]$ for each row $i$. 

\begin{exercise}\clabel{ex:on:3}
  Why do we require this?
  What is the interpretation of $P_{i 0} = 1-\sum_{i=1}^M P_{i j}$? What does it mean when $P_{i 0 } > 0$?
\begin{solution}
  A job leaving station $i$ has to go somewhere, either to another station or perhaps to station $i$ again, or it leaves the network altogether.
  When the summation is less than~$1$, jobs are allowed to leave the network.
  As $\sum_{i=1}^MP_{i j}$ is the probability to be sent to some station in the network, $P_{i 0} $ is the probability a job leaves the network.
  When $P_{i 0} > 0$, jobs do leave from station~$i$.
\end{solution}
\end{exercise}


Consider station $i$, say, and assume that jobs arrive as a Poisson process with rate $\lambda_i$.
Since service times are exponentially distributed, it follows from the previous section that the departure process is also Poisson with rate $\lambda_i$.
Then, after departure, jobs are sent with probability $P_{i j}$ to station~$j$, independent of anything else.
But then we can use~\cref{ex:1} to conclude that the jobs sent to station~$j$ form a Poisson processes with rate $\lambda_i P_{i j}$.
Now take the perspective of some station~$j$.
Suppose this station receives such thinned Poisson `streams' from all other stations.
Then observe that, by~\cref{ex:l-103}, this merged process is also a Poisson process with the combined rate of the individual `streams'.
Assuming that new jobs arrive at station~$j$ as a Poisson process with rate~$\gamma_j$, we can merge this process with the departure processes of the other stations to obtain the total arrival process at station~$j$, and this must again be Poisson and has rate
\begin{equation*}
\gamma_j + \sum_{i=1}^M \lambda_i P_{i j}.
\end{equation*}
Finally, since jobs arrive at station~$j$ as a Poisson process, and service times are exponential, the departure process of this station is also Poisson, and so on for all the stations in the network.
Thus, it is intuitively clear that we can model this network as a set of $M/M/1$ queues; below we will give a formal proof of this fact for two stations.
Note that we allow for external jobs arriving at any station.
Therefore this network is \recall{open}.
This differs from so-called \emph{emph} closed networks; in such networks jobs do not enter or leave.

It is evident that, when the network is stable (so that queues do not keep on increasing over time), all jobs that enter the network must eventually leave.
This insight leads us to the \recall{traffic (rate) equations}, which state that for all stations $i$, 
\begin{equation}
  \label{eq:101}
  \lambda_i = \gamma_i + \sum_{j=1}^M \lambda_j P_{j i}, \quad i = 1, \ldots, M,
\end{equation}
where the left-hand side represents the rate at which jobs depart and the right-hand side the rate at which jobs arrive. 

Let us for the moment assume that we can solve the traffic equations, in other words, we can find a set of numbers $\lambda =(\lambda_1, \ldots, \lambda_M)$ such that \cref{eq:101} is satisfied for given $\gamma =(\gamma_1, \ldots, \gamma_M)$ and routing matrix~$P$, cf.
\cref{sec:lambda-=-gamma}.
Then, we can define the load at station $i$ as $\rho_i = \lambda_i \E{S_i}$.
Clearly, we assume that $\rho_i < 1$ for all stations~$i$.
Moreover, station~$i$ being an $M/M/1$ queue, it follows that the sojourn time is $\E{W_i} = \E{S_i}/(1-\rho_i)$.
Write $|\gamma|= \sum_{i=1}^M \gamma_i$ as the total external arrival rate.
Then, using that the average total number of jobs is equal to the sum of the average number of jobs at each station, it must follow that
\begin{equation*}
 \E L = \sum_{i=1}^M \E{L_i}.
\end{equation*}
Then with an application of Little's law to the network as a whole and to each station individually, we get
\begin{equation*}
  |\gamma| \E W = \E L = \sum_{i=1}^M \E{L_i} = \sum_{i=1}^M \lambda_i \E{W_i}. 
\end{equation*}
As a last step, by dividing by $|\gamma|$, we can express the average sojourn time in the network in terms of the \emph{visiting ratios} $\lambda_i/|\gamma|$ as
\begin{equation*}
 \E W = \sum_{i=1}^M \frac{\lambda_i}{|\gamma|} \E{W_i}. 
\end{equation*}

\begin{exercise}\label{ex:on-5}
  Provide an interpretation for the above expression.
\begin{hint}
    What  is the intuition behind the visit ratios?
\end{hint}
\begin{solution}
  The visit ratio $\lambda_i/|\gamma|$ tells how often station $i$ is visited relative to the total number of arrivals.
  Thus, $\lambda_i \E{W_i} /|\gamma|$ is the amount of time an `average' job spends at station~$i$ before leaving.
\end{solution}
\end{exercise}

\begin{exercise}\clabel{ex:47}
We have a two-station single-server open network.
Jobs enter the network at the first station with rate $\gamma$.
A fraction $\alpha$ returns from station 1 to itself; the rest moves to station 2.
At station 2 a fraction $\beta_2$ returns to station 2 again, a fraction $\beta_1$ goes to station 1.

First, compute $\lambda$, then analyze what happens if $\alpha\to 1$ or $\beta_1\to 0$.
\begin{solution}
 \begin{equation*}
 P = 
 \begin{pmatrix}
 \alpha & 1- \alpha \\
 \beta_1 & \beta_2
 \end{pmatrix}.
 \end{equation*}

 \begin{equation*}
 (\lambda_1, \lambda_2) = (\gamma, 0) + (\lambda_1, \lambda_2) P.
 \end{equation*}
Solving first for $\lambda_2$ leads to $\lambda_2 = (1-\alpha) \lambda_1 + \beta_2 \lambda_2$, so that 
\begin{equation*}
 \lambda_2 = \frac{1-\alpha}{1-\beta_2} \lambda_1. 
\end{equation*}
Next, using this and that $\lambda_1 = \alpha \lambda_1 + \beta_1 \lambda_2 + \gamma$ gives with a bit of algebra
\begin{equation*}
 \begin{split}
\gamma 
&= \lambda_1(1-\alpha) - \beta_1\lambda_2 \\
&= \lambda_1\left(1-\alpha - \beta_1\frac{1-\alpha}{1-\beta_2}\right) \\
&= \lambda_1(1-\alpha)\left(1 - \frac{\beta_1 }{1-\beta_2}\right) \\
&= \lambda_1(1-\alpha)\frac{1-\beta_1-\beta_2 }{1-\beta_2}.
 \end{split}
\end{equation*}
Hence, 
\begin{equation*}
 \lambda_1 = \frac\gamma{1-\alpha}\frac{1-\beta_2}{1-\beta_1-\beta_2}. 
\end{equation*}
Thus, 
\begin{equation*}
 \lambda_2 = \frac{1-\alpha}{1-\beta_2} \lambda_1 = \frac\gamma{1-\beta_1-\beta_2}. 
\end{equation*}


We want of course that $\lambda_1 < \mu_1$ and $\lambda_2 < \mu_2$.
With the above expressions this leads to conditions on $\alpha$, $\beta_1$ and $\beta_2$.
Note that we have three parameters, and two equations; there is not a single condition from which the stability can be guaranteed.

If $\alpha\uparrow 1$, the arrival rate at node $1$ explodes.
If $\beta_1=0$ no jobs are sent from node 2 to node 1.
\end{solution}
\end{exercise}


\subsubsection*{Stationary distributions}

Above we derived expressions for the average waiting time in a network of $M/M/1$ queues.
In fact, it is possible to obtain the much stronger result that the stationary probability that the system contains $n=(n_1,n_2, \ldots, n_M)$ at stations $1,\ldots, M$ takes the form
\begin{equation*}
  \P{N_1=n_1, \ldots, N_M=n_M} = p(n) = \Pi_{i=1}^M p(n_i) = \Pi_{i=1}^M (1-\rho_i)\rho_i^{n_i},
\end{equation*}
where $p(n_i)=(1-\rho_i)\rho_i^{n_i}$ is the stationary probability that station~$i$ contains $n_i$ jobs, compare~\cref{eq:23}.
In words, $p(n)$ is equal to the product of the probabilities $p(n_i)$ of all of the stations $i=1,\ldots,M$.
But, this implies that $p(n_i)$ is \emph{independent} of the state of the other stations.
For notational ease, we will prove this for the case of two stations in tandem.
The general result is known as the fact that \recall{Jackson networks}, i.e., open networks of $M/M/c$ networks, admit a \recall{product-form solution}.
Note that these probabilities are useful to estimate excess probabilities such as $\P{L_1> n_1, L_2>n_2}$. 


Write $p(i,j)=\P{N_1=i, N_2=j}$ for the state of the two-station network to denote that station $1$ contains $i$ jobs and station $2$ contains $j$ jobs.
We have to show that the probabilities $p(i,j)$ satisfy the balance equations for all $i, j\geq 0$.
Recall that the balance equations express that, in steady state, the total (probability) rate out of a state must be equal to the (probability) rate into this state, cf.,~\cref{sec:level-cross-balance}.

\begin{extra}
  Provide the balance equation for state $(0,0)$ and check that this is satisfied by $p(0,0)$.
\begin{hint}
  Realize that an arrival is required to leave state $(0,0)$, and a departure at the second queue is necessary to enter state $(0,0)$.
\end{hint}
\begin{solution}
  Since $p(i,j) = (1-\rho_1)(1-\rho_2)\rho_1^i \rho_2^j$, we drop the normalization factor in the checks to come.

  The rate into state $(0,0)$ is $\mu_2 p(0,1) = \mu_2 \rho_2$. The rate out of state $(0,0)$ is $\lambda p(0,0) = \lambda$. Since $\rho_2=\lambda/\mu_2$, these two rates are the same.
\end{solution}
\end{extra}

\begin{extra}
  Provide the balance equations for  states $(i,0)$ with $i\geq 1$ and check that these are satisfied by $p(i,0)$. 
\begin{solution} We show that the rate out is the rate in.
  \begin{align*}
    \text{rate out } &=(\lambda + \mu_1) p(i,0) = \mu_1 \rho_1^i + \lambda \rho_1^i \\
                     &= \lambda \rho_1^{i-1} + \mu_2 \rho_1^i \rho_2 \\
    &= \lambda p(i-1,0) + \mu_2 p(i, 1) = \text{ rate in}.
  \end{align*}
\end{solution}
\end{extra}

\begin{extra}
  Provide the balance equations for states $(0,j)$ with $j\geq 1$ and check that these are satisfied by $p(0, j)$. 
\begin{solution} We show that the rate out is the rate in.
  \begin{align*}
    \text{rate out } &=(\lambda + \mu_2) p(0, j) = \mu_2 \rho_2^j + \lambda \rho_2^j\\
                     &= \mu_1\rho_1 \rho_2^{j-1} + \mu_2 \rho_2^{j+1} \\
    &= \mu_1 p(1,j-1) + \mu_2 p(0, j+1) = \text{ rate in}.
  \end{align*}
\end{solution}
\end{extra}

\begin{extra}
  Provide the balance equations for states $(i,j)$ with $i, j\geq 1$ and check that these are satisfied by $p(i, j)$. 
\begin{solution} We show that the rate out is the rate in.
  \begin{align*}
    \text{rate out } &=(\lambda + \mu_1 + \mu_2) p(i, j) \\
    &= \lambda  \rho_1^i \rho_2^j + \mu_1 \rho_1^{i} \rho_2^j + \mu_2 \rho_1^i\rho_2^j\\
    &=\mu_2 \rho_1^{i} \rho_2^{j+1} + \lambda \rho_1^{i-1} \rho_2^j + \mu_1 \rho_1^{i+1}\rho_2^{j-1}\\
                     &= \mu_2p(i, j+1) + \lambda p(i-1, j) + \mu_1 p(i+1, j-1)\\
    &= \text{ rate in}.
  \end{align*}
\end{solution}
\end{extra}

\begin{exercise}\label{ex:on-4}
  Provide the balance equations for states $(i,j)$ with $i, j\geq 0$ and check that these are satisfied by $p(i, j)$ for $i,j\geq 0$.
\begin{solution}
See the exercises above.  
\end{solution}
\end{exercise}




\opt{solutionfiles}{
\Closesolutionfile{hint}
\Closesolutionfile{ans}
\subsection*{Hints}
\input{hint}
\subsection*{Solutions}
\input{ans}
}
%\clearpage



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../companion"
%%% End:
